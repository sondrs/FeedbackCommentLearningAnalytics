{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b79168e-78cc-4e55-a14d-c1bd363e31a0",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ef28f7-f8d7-4547-8a07-6fd554a7cbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from joblib import dump, load\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.style.use('tableau-colorblind10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7cb6dc-c409-4c79-898a-b056a6d57847",
   "metadata": {},
   "source": [
    "# loading training corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cd273b-ce96-4815-a571-bed97acaa89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_corpus(path,n,m=0,letters='',ending='.txt',split=False,lower=False):\n",
    "    corpus = []\n",
    "    \n",
    "    for i in range(m,n):\n",
    "        filename = letters+f\"{i:06}\"+ending  \n",
    "        filepath = os.path.join(path, filename)\n",
    "        \n",
    "        if os.path.exists(filepath):\n",
    "            with open(filepath, 'r', encoding='utf-8') as file:\n",
    "                document = file.read()\n",
    "                if lower:\n",
    "                    document = document.lower()\n",
    "                if split:\n",
    "                    document = document.split(split)\n",
    "                corpus.append(document)\n",
    "                \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c415f40-bcbe-4cb9-a4ca-7796600a5586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLargeCorpus(loadComponents=False,\n",
    "                   writeFile=False,\n",
    "                  openCorpus = True):\n",
    "    if loadComponents:\n",
    "        # Loading training corpora\n",
    "        #NOREC\n",
    "        path = \"resources/norec/data/train/\"\n",
    "        norec = load_corpus(path,700000)\n",
    "\n",
    "        #Kristiania course evaluations\n",
    "        filename = 'Evaluation_2020_2021-1'\n",
    "        path = 'Input/'\n",
    "        kristiania = pd.read_csv(path+filename+'.csv', low_memory=False).Comments.dropna().tolist()\n",
    "\n",
    "        #parliament speeches\n",
    "        path = 'resources/talk-of-norway/'\n",
    "        stortinget = pd.read_csv(path+'ton_updated.csv').text.tolist()\n",
    "\n",
    "        corpus = norec+stortinget+kristiania\n",
    "        len(corpus)\n",
    "        return corpus\n",
    "    if writeFile:\n",
    "        import re\n",
    "        with open('resources/trainingData/combinedTrainingCorpus.txt','w') as file:\n",
    "            for row in corpus: \n",
    "                file.write(re.sub('\\n',' ',row))\n",
    "                file.write('\\n')\n",
    "    if openCorpus:\n",
    "        with open('resources/trainingData/combinedTrainingCorpus.txt','r') as file:\n",
    "            corpus = file.read().split('\\n')\n",
    "        return corpus\n",
    "corpus = getLargeCorpus(openCorpus=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3613e827-4fa7-418b-bbd2-ec9d50045ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaUpdater:\n",
    "    def __init__(self):\n",
    "        self.lemmaReg = {}\n",
    "\n",
    "    def update(self, speech):\n",
    "        \"\"\"Update lemmaReg based on the provided speech.\"\"\"\n",
    "        for word in speech:\n",
    "            if type(word) == list and len(word) > 3:\n",
    "                if word[1] != word[2]:\n",
    "                    if word[1] not in self.lemmaReg and word[1].isalnum():\n",
    "                        self.lemmaReg[word[1]] = word[2]\n",
    "        #return self.lemmaReg\n",
    "    def getLemmas(self):\n",
    "        return self.lemmaReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcff43d-e4a7-43a5-b8c9-fc1189710045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create combined preprocessed training corpus including lemmatization\n",
    "def getLargeLemmatizer(getLemmas=False,\n",
    "                      writeToDisk=False,\n",
    "                      importLemmas=True):\n",
    "    if getLemmas:\n",
    "        updater = LemmaUpdater()\n",
    "        from datetime import datetime\n",
    "        from tqdm import tqdm\n",
    "        path = 'resources/talk-of-norway/annotations/'\n",
    "        totalNumber=251000\n",
    "        batchSize=10000\n",
    "        main_bar = tqdm(total=totalNumber/batchSize,desc='Learning lemmatizations',leave=True)\n",
    "        main_bar.update(0)\n",
    "\n",
    "        for i in range(round(totalNumber/batchSize)):\n",
    "            print('loading batch '+str(i)+' of '+str(totalNumber/batchSize))\n",
    "            tonAnnot = load_corpus(path,\n",
    "                                   i*batchSize,\n",
    "                                   i*batchSize-batchSize,\n",
    "                                   'tale',\n",
    "                                   '.tsv',\n",
    "                                   '\\n',\n",
    "                                   lower=True)\n",
    "\n",
    "            sub_bar = tqdm(total=len(tonAnnot)-1, desc=\"Processing batch\", leave=True)\n",
    "            sub_bar.update(0)\n",
    "            batch_beg = datetime.now()\n",
    "            for i,speech in enumerate(tonAnnot):\n",
    "                processed = [item.split('\\t') for item in speech]\n",
    "                updater.update(processed)\n",
    "                if i%1000==0:\n",
    "                    sub_bar.update(i)\n",
    "            batch_end = datetime.now()\n",
    "            sub_bar.close()\n",
    "            lemmaReg = updater.getLemmas()\n",
    "            print('spent:',batch_end-batch_beg)\n",
    "            print('n keys:',len(lemmaReg.keys()))\n",
    "            print('n lemmas:',len(set(lemmaReg.values())))\n",
    "            main_bar.update(i)\n",
    "    if writeToDisk:\n",
    "        print('writing to disk')\n",
    "        filename = ('trainedLemmatizer'\n",
    "                    '.csv')\n",
    "        pd.DataFrame(lemmaReg,index=['lemmatized']).T.reset_index().to_csv('resources/fittedModels/'+filename,index=False)\n",
    "        print('done, and written to disk as '+filename)\n",
    "    if importLemmas:\n",
    "        import pandas as pd\n",
    "        lemmaReg = dict(zip(pd.read_csv(\n",
    "            'resources/fittedModels/trainedLemmatizer.csv')['index'],pd.read_csv(\n",
    "            'resources/fittedModels/trainedLemmatizer.csv')['lemmatized']))\n",
    "    return lemmaReg\n",
    "\n",
    "lemmaReg = getLargeLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233955d6-f9ac-4df3-b644-c70f9bc21073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "print(tabulate(\n",
    "    pd.DataFrame(\n",
    "        lemmaReg,index=['Lemmatized']).T.reset_index().rename(\n",
    "        columns={'index':'Word'}).set_index('Word').iloc[:10,:],tablefmt='latex'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639c2915-4075-48bc-9242-1092004901b5",
   "metadata": {},
   "source": [
    "# Preprocessing training corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55c03fb-3798-4c8e-a1ea-b85ae043ed86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "#creating functions for preprocessing, tailoring them to work \n",
    "#with norwegian language and this dataset in particular\n",
    "\n",
    "\n",
    "def preprocessFunction(corpusToProcess):\n",
    "    \n",
    "    from collections import Counter\n",
    "    import re\n",
    "    lemmaReg = getLargeLemmatizer()\n",
    "    \n",
    "    with open('resources/fittedModels/stopwords_from_corpus.txt','r') as stopfile:\n",
    "            stops = stopfile.read().split('\\n')\n",
    "    \n",
    "    def stopTester(w):\n",
    "        \"\"\"taking a string consiting of one word and possibly punctuation\n",
    "        and returning the word and if present the punctuation \n",
    "        (.,!? or combinations) \n",
    "        as two elements of a list. Additionally, if the word has a lemmatized\n",
    "        form in the lemmaReg input, that form is returned\"\"\"\n",
    "        w = list(w)\n",
    "        t=[]\n",
    "        while w and w[-1] in ['.',',','!','?']:\n",
    "            t.append(w.pop())\n",
    "        w = ''.join(w)\n",
    "        #\n",
    "        t = ''.join(t)\n",
    "        return [w,t]\n",
    "\n",
    "    def tokenizer(doc):\n",
    "        \"\"\"taking a string containing a sentence/document,\n",
    "        splitting on words and removing special characters\"\"\"\n",
    "        removeChars = '[^A-Za-z0-9.æäöøåÆØÅÄÖ]'\n",
    "        #removeChars1 = '[^A-Za-z0-9.]'\n",
    "        tokens = []\n",
    "        for word in doc.lower().split():\n",
    "            if word[-1:].isalnum():\n",
    "                word = re.sub(removeChars,'',word)\n",
    "                tokens.append(word) \n",
    "            else:\n",
    "                words = stopTester(word)\n",
    "                word = re.sub(removeChars,'',words[0])\n",
    "                tokens.append(word)\n",
    "                tokens.append(words[1])     \n",
    "        return tokens\n",
    "\n",
    "    def wordCounter(doc):\n",
    "        \"\"\"\"taking a tokenized document, returning \n",
    "        individual word count\"\"\"\n",
    "        return Counter(doc)\n",
    "\n",
    "    #creating the preprocessing function to perform all preprocessing \n",
    "    #tasks with one document\n",
    "    def preprocess(doc,stops,lemmaReg):\n",
    "        \"\"\"taking a non-tokenized document and a list of stopwords,\n",
    "        returning a preprocessed (tokenized) document\"\"\"\n",
    "        if type(doc) == str:\n",
    "\n",
    "            return (' ').join([str(lemmaReg.get(word,word)) for word in tokenizer(doc) if word \n",
    "                    and word not in stops])\n",
    "        else:\n",
    "            return doc\n",
    "    \n",
    "    from tqdm import tqdm\n",
    "    main_bar = tqdm(total=len(corpusToProcess),desc='cleaning, tokenizing, removing stopwords, lemmatizing',leave=True)\n",
    "    main_bar.update(0)\n",
    "    from datetime import datetime\n",
    "    t0=datetime.now()\n",
    "    corpus_preprocessed = []\n",
    "    for i,doc in enumerate(corpusToProcess):\n",
    "        corpus_preprocessed.append((preprocess(doc,stops,lemmaReg)))\n",
    "        if i%10000 == 0:\n",
    "            main_bar.update(i)\n",
    "    t1=datetime.now()\n",
    "    main_bar.close()\n",
    "    print('done, samples:',len(corpusToProcess))\n",
    "    print('time:',t1-t0)\n",
    "    return corpus_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8270485-2676-4188-a3b0-acb4a0a7f82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPreprocessedCorpus(preprocessCorpus=False,\n",
    "                          writePreprocessedCorpus=False,\n",
    "                          readPreprocessedCorpus=True):\n",
    "    if preprocessCorpus:\n",
    "        corpus_preprocessed = preprocessFunction(corpus)\n",
    "        #with open('resources/fittedModels/stopwords_from_corpus.txt','r') as stopfile:\n",
    "        #    stops = stopfile.read().split('\\n')\n",
    "\n",
    "        #corpusToProcess = corpus\n",
    "        #from tqdm import tqdm\n",
    "        #main_bar = tqdm(total=len(corpusToProcess),desc='cleaning, tokenizing, removing stopwords, lemmatizing',leave=True)\n",
    "        #main_bar.update(0)\n",
    "        #from datetime import datetime\n",
    "        #t0=datetime.now()\n",
    "        #corpus_preprocessed = []\n",
    "        #for i,doc in enumerate(corpusToProcess):\n",
    "        #    corpus_preprocessed.append((preprocess(doc,stops,lemmaReg)))\n",
    "        #    if i%10000 == 0:\n",
    "        #        main_bar.update(i)\n",
    "        #t1=datetime.now()\n",
    "        #main_bar.close()\n",
    "        #print('done, samples:',len(corpusToProcess))\n",
    "        #print('time:',t1-t0)\n",
    "        if writePreprocessedCorpus:\n",
    "            print('writing to disk')\n",
    "            with open('resources/trainingData/combinedTrainingCorpus_preprocessed.txt','w') as file:\n",
    "                for row in corpus: \n",
    "                    file.write(row)\n",
    "                    file.write('\\n')\n",
    "            print('done')\n",
    "    if readPreprocessedCorpus:\n",
    "        with open('resources/trainingData/combinedTrainingCorpus_preprocessed.txt','r') as file:\n",
    "            corpus = file.read().split('\\n')\n",
    "            print('read preprocessed corpus for training from file')\n",
    "            print('corpus length',len(corpus))\n",
    "    return corpus\n",
    "\n",
    "corpus = getPreprocessedCorpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef4b897-8ec7-4031-ab63-54b8ab4fe234",
   "metadata": {},
   "source": [
    "# creating models (tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50197bb2-657d-4b3f-a48c-43049d97f423",
   "metadata": {},
   "source": [
    "### Learning a large norwegian vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ca9600-615b-4101-82fe-83dfce15798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from joblib import dump, load\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, lil_array, hstack, vstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6917991d-7924-4934-b567-ce3f0774cb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLargeVocabulary(learnVocabulary=True,\n",
    "                  min_df = 1,\n",
    "                 corpus=corpus,\n",
    "                 lemmas=lemmaReg):\n",
    "    if learnVocabulary:\n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        import numpy as np\n",
    "\n",
    "        vectorizer = TfidfVectorizer(min_df=min_df)\n",
    "        tfidf_matrix = vectorizer.fit_transform(corpus).astype(np.float32)\n",
    "        print('learnt the vocabulary from the docs')\n",
    "        del tfidf_matrix\n",
    "        del corpus\n",
    "        return set([lemmas.get(word,word) for word in vectorizer.get_feature_names_out().tolist() if word.isalpha()])\n",
    "vocabularyLearned = getLargeVocabulary(learnVocabulary=True, min_df=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef278024-6346-4aec-8b6b-bba7824663dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocabularyLearned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6020d05e-36d1-4883-95b9-83078e98a1fd",
   "metadata": {},
   "source": [
    "### supplementing with __all__ words (lemmatized form) except stopwords from the kristiania data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b251a514-8639-4216-875c-9ace9485e4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabSize = 16000\n",
    "nComps = 300 # 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2143153-05a8-42e3-ad15-5259102545cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCombinedVocab(createCombinedVocabulary = False,\n",
    "                        writeCombinedVocabulary = False,\n",
    "                        importVocabulary = True,\n",
    "                        vocabularyLearned=vocabularyLearned,\n",
    "                       lenStr=16000):\n",
    "    if createCombinedVocabulary:\n",
    "        with open('resources/trainingData/vocabulary_from_corpus.txt','r') as file:\n",
    "            vocabularyCorpus = file.read().split('\\n')\n",
    "        vocabularyCorpus = set([lemmaReg.get(word,word) for word in vocabularyCorpus if word.isalpha()])\n",
    "        vocabulary = vocabularyLearned | vocabularyCorpus\n",
    "        del vocabularyLearned, vocabularyCorpus\n",
    "        lenStr = len(vocabulary)\n",
    "        print('combined vocabulary, length',lenStr)\n",
    "        if writeCombinedVocabulary:\n",
    "            with open('resources/fittedModels/vocabularyTotal_'+str(lenStr)+'_.txt','w') as file:\n",
    "                file.write('\\n'.join(vocabulary))\n",
    "            print('wrote combined vocabulary to disk')\n",
    "    if importVocabulary:\n",
    "        with open('resources/fittedModels/vocabularyTotal_'+\n",
    "                  str(lenStr)+\n",
    "                  '.txt','r') as file:\n",
    "            vocabulary = file.read().split('\\n')\n",
    "            print('read the total vocabulary from file')\n",
    "    vocabularyIdx = {v:k for k,v in enumerate(vocabulary)}\n",
    "    \n",
    "    print(str(len(vocabulary)))\n",
    "\n",
    "    return vocabulary, vocabularyIdx\n",
    "\n",
    "vocabulary,vocabularyIdx = createCombinedVocab(createCombinedVocabulary = False,\n",
    "                        writeCombinedVocabulary = False,\n",
    "                        importVocabulary = True,\n",
    "                         lenStr=vocabSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b17efa-6c59-4d8a-ad0e-6b64c569af33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotCumVar(svd,\n",
    "               modelType = 'Tfidf',\n",
    "              saveFig=True):\n",
    "    lenStr = svd.n_features_in_\n",
    "    n_components = svd.n_components\n",
    "    filename=('CumVar_svd'\n",
    "                +str(n_components)\n",
    "                +'_'\n",
    "              +modelType\n",
    "              +'_'\n",
    "                +str(lenStr)\n",
    "                +'.png')\n",
    "    import numpy as np\n",
    "    cumulative_variance = np.cumsum(svd.explained_variance_ratio_)\n",
    "    n_components = svd.n_components\n",
    "    fig, cumVar = plt.subplots(1,1,figsize=(5,3.5),dpi=240)\n",
    "    cumVar.plot(range(n_components), cumulative_variance)\n",
    "    cumVar.set_xlabel('Number of Components')\n",
    "    cumVar.set_ylabel('Cumulative Explained Variance')\n",
    "    cumVar.set_title('Cumulative Variance Explained')\n",
    "    cumVar.set_ylim(0,1)\n",
    "    cumVar.grid(True)\n",
    "    if saveFig:\n",
    "        plt.savefig('results and diagrams/'+filename)\n",
    "        print('saved figure as '+filename)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84a2ba1-35e5-411b-8bff-985ab1ef717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVectorizerSVDmatrix(trainSVD=False,\n",
    "                           writeSVD=False,\n",
    "                           fitVectorizer=False,\n",
    "                           writeVectorizer=False,\n",
    "                           readVectorizer=True,\n",
    "                           writeTfidf=False,\n",
    "                           readTfidf=False,\n",
    "                           readSVD=True,\n",
    "                          vocabularyIdx=vocabularyIdx,\n",
    "                          corpus=corpus,\n",
    "                           comps=nComps,\n",
    "                           lenStr=vocabSize\n",
    "                          ):\n",
    "    tfidf_matrix=np.array([0])\n",
    "    \n",
    "    lenStr = len(vocabularyIdx)\n",
    "    if fitVectorizer:\n",
    "        print('fitting tfidf')\n",
    "        vectorizer = TfidfVectorizer(vocabulary=vocabularyIdx)\n",
    "        tfidf_matrix = vectorizer.fit_transform(corpus).astype(np.float32)\n",
    "\n",
    "\n",
    "    if writeVectorizer:\n",
    "        dump(vectorizer, 'resources/fittedModels/fittedTfidfVectorizer_'\n",
    "             +str(lenStr)\n",
    "             +'.joblib')\n",
    "        print('stored trained TfidfVectorizer to disk') \n",
    "\n",
    "    if readVectorizer:\n",
    "        vectorizer = load('resources/fittedModels/fittedTfidfVectorizer_'\n",
    "             +str(lenStr)\n",
    "             +'.joblib')\n",
    "        print('read trained TfidfVectorizer from disk') \n",
    "\n",
    "    if writeTfidf:\n",
    "        dump(tfidf_matrix, 'resources/trainingData/tfidf_matrix_training_data_'\n",
    "             +str(lenStr)\n",
    "             +'.joblib')\n",
    "        print('stored Tfidf matrix to disk') \n",
    "\n",
    "    if readTfidf:\n",
    "        tfidf_matrix = load('resources/trainingData/tfidf_matrix_training_data_'\n",
    "             +str(lenStr)\n",
    "             +'.joblib')\n",
    "        print('read Tfidf matrix from disk') \n",
    "\n",
    "    if trainSVD:\n",
    "        from sklearn.decomposition import TruncatedSVD\n",
    "        #comps = comps\n",
    "        n_components = comps\n",
    "        print('fitting svd')\n",
    "        svd_tfidf = TruncatedSVD(n_components=n_components)\n",
    "        tfidf_reduced = svd_tfidf.fit_transform(tfidf_matrix)\n",
    "        del tfidf_matrix\n",
    "        print('fitted svd to reduce Tfidf Matrix')\n",
    "        print(tfidf_reduced.shape) \n",
    "        print(svd_tfidf.explained_variance_ratio_.sum())\n",
    "    if writeSVD:\n",
    "        dump(svd_tfidf, 'resources/fittedModels/fittedSVD_'\n",
    "             +str(lenStr)\n",
    "             +'_'\n",
    "             +str(comps)\n",
    "             +'.joblib')\n",
    "        print('stored fitted svd to reduce Tfidf Matrix to disk')\n",
    "    if readSVD:\n",
    "        #lenStr = 34019\n",
    "        #comps = 490\n",
    "        svd_tfidf = load('resources/fittedModels/fittedSVD_'\n",
    "             +str(lenStr)\n",
    "             +'_'\n",
    "             +str(comps)\n",
    "             +'.joblib')\n",
    "        print('read fitted svd to reduce Tfidf Matrix from disk')\n",
    "    return vectorizer, svd_tfidf\n",
    "\n",
    "\n",
    "vectorizer, svd_tfidf = getVectorizerSVDmatrix(\n",
    "                            trainSVD=True,\n",
    "                           writeSVD=True,\n",
    "                           fitVectorizer=True,\n",
    "                           writeVectorizer=True,\n",
    "                           readVectorizer=False,\n",
    "                           writeTfidf=False,\n",
    "                           readTfidf=False,\n",
    "                           readSVD=False,\n",
    "                          vocabularyIdx=vocabularyIdx,\n",
    "                          corpus=corpus,\n",
    "                           comps=nComps,\n",
    "                           lenStr=vocabSize) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82af7562-a435-478f-9763-5de49d0f33bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_tfidf.n_features_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a655da-08a1-49ba-91a0-55389bd4b60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCumVar(svd = svd_tfidf,\n",
    "           modelType='tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974b6d32-b650-44bb-a601-4a303bee8e23",
   "metadata": {},
   "source": [
    "# Specific training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297347a4-694b-4404-a4d6-37494498d53b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sentencesLabeled = pd.read_csv(\n",
    "    'resources/trainingData/first_semester_training_data_sentimentTopicLabeled_raw.csv',\n",
    "                                    delimiter=';',\n",
    "                        ).rename(\n",
    "    columns={'Unnamed: 0':'sentIdx',\n",
    "            #'sentence':'sentencePreprocessed',\n",
    "            'label':'sentimentLabel'}).dropna(subset = ['sentenceRaw'])\n",
    "print(sentencesLabeled.shape, sentencesLabeled.iloc[-1,1])\n",
    "\n",
    "#prep func\n",
    "\n",
    "sentencesLabeled['sentencePreprocessed'] = preprocessFunction(sentencesLabeled.sentenceRaw)\n",
    "\n",
    "def labelCorrect(l):\n",
    "    if l.lower()=='pos':\n",
    "        return 'Positive'\n",
    "    if l.lower()=='neut':\n",
    "        return 'Neutral'\n",
    "    if l.lower()=='neg':\n",
    "        return 'Negative'\n",
    "\n",
    "sentencesLabeled.sentimentLabel = [labelCorrect(l) for l in sentencesLabeled.sentimentLabel]\n",
    "#lemmaReg = dict(zip(pd.read_csv('resources/fittedModels/trainedLemmatizer.csv')['index'],pd.read_csv('resources/fittedModels/trainedLemmatizer.csv')['lemmatized']))\n",
    "\n",
    "#sentencesLabeled.sentencePreprocessed = [[lemmaReg.get(word,word) for word in document] if type(document)==list else document for document in sentencesLabeled.sentencePreprocessed]\n",
    "sentencesLabeled['topicLabel'] = [item.split(', ') if type(item)==str else [''] for item in sentencesLabeled.topicLabel]\n",
    "sentencesLabeled['sentimentLabel'] = [item.split(', ') if type(item)==str else [''] for item in sentencesLabeled.sentimentLabel]\n",
    "sentencesLabeled['sentimentLabel'] = [[''] if item==['Neutral'] else item for item in sentencesLabeled.sentimentLabel]\n",
    "trainSentencesLabeled = sentencesLabeled.loc[:round(0.8*sentencesLabeled.shape[0])].copy()\n",
    "testSentencesLabeled = sentencesLabeled.loc[round(0.8*sentencesLabeled.shape[0]):].copy()\n",
    "trainSentencesLabeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7feecf-c4a3-4098-b1f5-26fffe971dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = vocabularyIdx\n",
    "\n",
    "trainSentencesTFIDF = vectorizer.transform(trainSentencesLabeled.sentencePreprocessed.tolist())\n",
    "trainSentences_reduced_by_svd = svd_tfidf.transform(trainSentencesTFIDF)\n",
    "print(trainSentencesTFIDF.shape)\n",
    "print(trainSentences_reduced_by_svd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a3bdf0-eacc-4a93-a1fb-a891b176d506",
   "metadata": {},
   "outputs": [],
   "source": [
    "testSentencesTFIDF = vectorizer.transform(testSentencesLabeled.sentencePreprocessed.tolist())\n",
    "testSentences_reduced_by_svd = svd_tfidf.transform(testSentencesTFIDF)\n",
    "print(testSentencesTFIDF.shape)\n",
    "print(testSentences_reduced_by_svd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1367cb2-d261-4a25-9b1e-b20a44905851",
   "metadata": {},
   "outputs": [],
   "source": [
    "[testSentencesTFIDF] == [np.array([0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3417a23b-0f0f-4973-a651-176ad1bfbd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#production class\n",
    "\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "class LabelModelTrainer:\n",
    "    \"\"\"a collection of functions to take an iterable holding \n",
    "    training labels, an iterable holding individual document \n",
    "    representations in array shape and returning a trained \n",
    "    model for label prediction\"\"\"\n",
    "    def __init__(self, \n",
    "                 label='', \n",
    "                 labels='', \n",
    "                 representations=[],\n",
    "                 vocabSize=16000,\n",
    "                 nComps=300\n",
    "                 ):#, svd1=None, a=False, svd2=None, b=False):\n",
    "        from numpy import array\n",
    "        from scipy.sparse import csr_matrix\n",
    "        \n",
    "        \n",
    "        if label and type(labels)!=str and type(representations)!=list:\n",
    "            self.label = label\n",
    "            self.labels = labels\n",
    "            self.representations = representations\n",
    "            self.labelCentroid, self.othersCentroid, self.mask = self.learnCentroids() #getCentroids\n",
    "            self.boolLabels = [1 if self.label in item else 0 for item in [[item] if not type(item)==list else item for item in self.labels]]\n",
    "        elif label:\n",
    "            self.label = label\n",
    "            self.vocabSize = vocabSize\n",
    "            self.nComps = nComps\n",
    "            self.labelCentroid, self.othersCentroid = self.loadCentroids(self.vocabSize,\n",
    "                                                                         self.nComps,\n",
    "                                                                        self.label)\n",
    "        else:\n",
    "            pass\n",
    "   \n",
    "\n",
    "    def learnCentroids(self): #getCentroids\n",
    "        from numpy import array, zeros\n",
    "        from scipy.sparse import csr_matrix\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "        representations = self.representations\n",
    "       \n",
    "        labeled = self.labels\n",
    "        \n",
    "        mask = array([(self.label in item) if type(item)==list else False for item in labeled])\n",
    "        if sum(mask)==0:\n",
    "            labelCentroid = zeros(representations.shape[1])+99\n",
    "            othersCentroid = zeros(representations.shape[1])-99\n",
    "            print('no items found with mask on '+str(self.label))\n",
    "        else:\n",
    "            labelCentroid = representations[mask].mean(axis=0)\n",
    "            othersCentroid = representations[~mask].mean(axis=0)\n",
    "\n",
    "        return labelCentroid, othersCentroid, mask\n",
    "    \n",
    "    def loadCentroids(self, vocabSize, nComps, label):\n",
    "        if nComps!=0:\n",
    "            rep = 'svd'\n",
    "        else:\n",
    "            rep = 'tfidf'\n",
    "        labelCentroid = load('resources/trainedClassifiers/centroids_vocabSize_'+str(vocabSize)+'_all.joblib')[rep][label]['labelCentroid']\n",
    "        othersCentroid= load('resources/trainedClassifiers/centroids_vocabSize_'+str(vocabSize)+'_all.joblib')[rep][label]['othersCentroid']\n",
    "        return labelCentroid, othersCentroid\n",
    "        \n",
    "    def getLabelScoresCosine(self, representations):\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        import numpy as np\n",
    "        if type(representations) != np.ndarray:\n",
    "            representations = representations.toarray()\n",
    "        labelScores = MinMaxScaler().fit_transform(np.asarray(\n",
    "            representations.dot((\n",
    "            self.labelCentroid - self.othersCentroid).reshape(-1,1))))\n",
    "        \n",
    "        self.probabilities = labelScores        \n",
    "\n",
    "        return labelScores\n",
    "\n",
    "    def predictCosine(self, representations, threshold=0.5):        \n",
    "        labelScores = self.getLabelScoresCosine(representations)\n",
    "        predictions = [[self.label] if score>threshold else [None] for score in labelScores]\n",
    "        self.predictions = predictions\n",
    "        self.representationsTest = representations\n",
    "        return predictions\n",
    "    \n",
    "    def getLabelScoresEuclidean(self, representations):\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        import numpy as np\n",
    "        if type(representations) != np.ndarray:\n",
    "            representations = representations.toarray()\n",
    "\n",
    "        distances_to_label = np.linalg.norm(representations - self.labelCentroid, axis=1)\n",
    "        distances_to_others = np.linalg.norm(representations - self.othersCentroid, axis=1)\n",
    "        \n",
    "        similarity_label = 1 / (1 + distances_to_label)\n",
    "        similarity_others = 1 / (1 + distances_to_others)\n",
    "        \n",
    "        scores = similarity_label / (similarity_label + similarity_others)\n",
    "         \n",
    "        self.probabilities = scores  \n",
    "\n",
    "        return scores\n",
    "    \n",
    "    def predictEuclidean(self, representations, threshold=0.5):\n",
    "               \n",
    "        scores = self.getLabelScoresEuclidean(representations)\n",
    "        \n",
    "        predictions = [[self.label] if score >= threshold else [None] for score in scores]\n",
    "        self.representationsTest = representations\n",
    "        self.predictions = predictions\n",
    "        return predictions\n",
    "    \n",
    "    def trainKnn(self, k=3):\n",
    "        \n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "        self.knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        self.knn.fit(self.representations, self.boolLabels)\n",
    "    \n",
    "    def predictKnn(self, representations):\n",
    "        \n",
    "        if not hasattr(self, 'knn'):\n",
    "            raise ValueError(\"train knn first\")\n",
    "\n",
    "        predictions = self.knn.predict(representations)\n",
    "        \n",
    "        label_predictions = [[self.label] if pred == 1 else [None] for pred in predictions]\n",
    "        \n",
    "        return label_predictions\n",
    "    \n",
    "    def predictKnnProb(self, representations):\n",
    "        \n",
    "        if not hasattr(self, 'knn'):\n",
    "            raise ValueError(\"train knn first\")\n",
    "\n",
    "        predictionsProb = self.knn.predict_proba(representations)[:,1]\n",
    "        self.probabilities = predictionsProb        \n",
    "        return predictionsProb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45aeff9-fa13-4582-bfea-7b47f82d2dbd",
   "metadata": {},
   "source": [
    "### Training on train set, predicting on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0ce47b-e509-4e77-8cba-aed18beea268",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#production all in one training of model on training data + test of performance on test data\n",
    "trainingReps =  {'tfidf':trainSentencesTFIDF, \n",
    "        'svd':trainSentences_reduced_by_svd}\n",
    "testingReps = {'tfidf':testSentencesTFIDF,\n",
    "              'svd':testSentences_reduced_by_svd}\n",
    "\n",
    "predictors = ['Cosine','Euclidean','Knn']\n",
    "\n",
    "TK = range(3,9)\n",
    "#sp = split\n",
    "\n",
    "\n",
    "labels = {'sentiment':['Positive','Negative'],\n",
    "          'topic': ['administrativt','digitalt','eksamen','foreleser','karakter',\n",
    "                    'korona','pensum','språk','undervisningsopplegget']}\n",
    "\n",
    "\n",
    "iterationNames = []\n",
    "numericScoresContainer = {}\n",
    "for k in labels: \n",
    "    for rep in ['tfidf','svd']: \n",
    "        for predictor in predictors:\n",
    "            trainSentencesLabeled = trainSentencesLabeled.copy()\n",
    "            for tk in TK: \n",
    "                if predictor in ['Cosine','Euclidean']:\n",
    "                    variString = '_T'\n",
    "                    tkA = tk/10\n",
    "                    numericScoresContainerLabel = 'predicted'+k.capitalize()+'_'+rep+'_'+predictor                \n",
    "                if predictor == 'Knn':\n",
    "                    variString = '_K'\n",
    "                    tkA = tk\n",
    "                    numericScoresContainerLabel = 'predicted'+k.capitalize()+'_'+rep+'_'+predictor+variString+str(tkA)\n",
    "                \n",
    "                iterationName = 'predicted'+k.capitalize()+'_'+rep+'_'+predictor+variString+str(tkA)\n",
    "                iterationNames.append(iterationName)\n",
    "                testSentencesLabeled[iterationName] = [[None]]*testSentencesLabeled.shape[0]\n",
    "\n",
    "                for label in labels[k]:\n",
    "                    #initialize model for the specific label and the specific reps \n",
    "                    lmt = LabelModelTrainer(label,\n",
    "                                            trainSentencesLabeled[k+'Label'],  \n",
    "                                            trainingReps[rep])\n",
    "\n",
    "                    if predictor == 'Cosine':\n",
    "                        predicted = lmt.predictCosine(testingReps[rep],tkA)\n",
    "                        numericScoresContainer[numericScoresContainerLabel] = (lmt.getLabelScoresCosine(testingReps[rep])).ravel()\n",
    "                        \n",
    "                    if predictor == 'Euclidean':\n",
    "                        predicted = lmt.predictEuclidean(testingReps[rep],tkA)\n",
    "                        numericScoresContainer[numericScoresContainerLabel] = (lmt.getLabelScoresEuclidean(testingReps[rep])).ravel()\n",
    "                        \n",
    "                    if predictor == 'Knn':\n",
    "                        #training:\n",
    "                        lmt.trainKnn(k=tkA)\n",
    "                        #predicting\n",
    "                        predicted = lmt.predictKnn(testingReps[rep])\n",
    "                        numericScoresContainer[numericScoresContainerLabel] = (lmt.predictKnnProb(testingReps[rep])).ravel()\n",
    "\n",
    "\n",
    "                    #storing in column\n",
    "                    testSentencesLabeled[iterationName] = [item+predicted[i] \n",
    "                                                    for i,item \n",
    "                                                    in \n",
    "                                                    enumerate(\n",
    "                                                        testSentencesLabeled[iterationName])]\n",
    "\n",
    "\n",
    "                #cleaning column - rules based for sentiment, aggregate for topics\n",
    "                if k=='sentiment':\n",
    "                    predicted = []#[None]*testSentencesLabeled.shape[0]\n",
    "                    for cell in testSentencesLabeled[iterationName]:\n",
    "                        result = 'Neutral'\n",
    "                        if 'Positive' in cell:\n",
    "                            if not 'Negative' in cell:\n",
    "                                result = 'Positive'\n",
    "                        if 'Negative' in cell:\n",
    "                            if not 'Positive' in cell:\n",
    "                                result = 'Negative'\n",
    "                        predicted.append(result.split())\n",
    "                    testSentencesLabeled[iterationName] = predicted\n",
    "                if k=='topic':\n",
    "                    testSentencesLabeled[iterationName] = [pd.Series(cell).dropna().values \n",
    "                                                            for cell in testSentencesLabeled[iterationName]]\n",
    "\n",
    "testSentencesLabeled = testSentencesLabeled.replace(np.nan, '');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faed168d-d835-44af-b73b-e6604ca2da35",
   "metadata": {},
   "outputs": [],
   "source": [
    "testSentencesLabeled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271a8c5f-8a00-41c6-815d-17790901eac0",
   "metadata": {},
   "source": [
    "### Evaluating predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2e2ff2-9f7e-40cd-b58e-1aafb9e52d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "allModelRuns = testSentencesLabeled.columns.drop(['sentIdx', 'docIdx','sentenceRaw',  'sentencePreprocessed', 'sentimentLabel',\n",
    "       'topicLabel']).tolist()\n",
    "\n",
    "topics = labels['topic']+['averageTopic']\n",
    "sentiments= labels['sentiment']+['averageSentiment']\n",
    "avg = ['average']\n",
    "indexFrame = pd.DataFrame({'labelType':['topic']*len(topics)+['sentiment']*len(sentiments)+['average']*len(avg),\n",
    "                   'label':topics+sentiments+avg})\n",
    "mIndex = pd.MultiIndex.from_frame(indexFrame)\n",
    "\n",
    "metrics = ['accuracy',\n",
    "           'falseClassRate',\n",
    "           'falseNassRate']\n",
    "modelList = []\n",
    "for item in allModelRuns:\n",
    "    if 'sentiment' in item.lower():\n",
    "        modelName = item.replace('Sentiment','')\n",
    "    if 'topic' in item.lower():\n",
    "        modelName = item.replace('Topic','')\n",
    "    if not modelName in modelList:\n",
    "        modelList.append(modelName)\n",
    "\n",
    "modelsCol = []\n",
    "for item in modelList:\n",
    "    for i in range(len(metrics)):\n",
    "        modelsCol.append(item)\n",
    "\n",
    "metricList = []\n",
    "for item in modelList:\n",
    "    for i in metrics:\n",
    "        metricList.append(i)\n",
    "cIndex = pd.MultiIndex.from_frame(pd.DataFrame({'metrics':metricList,\n",
    "                                                'model':modelsCol}))\n",
    "resultsFrame = pd.DataFrame(index=cIndex,columns=mIndex).T\n",
    "lookupLabels = {v:k for k,v in resultsFrame.index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb7778c-6f18-453d-ae77-675472cc5972",
   "metadata": {},
   "outputs": [],
   "source": [
    "testSentencesLabeled.loc[2723]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c76e8b-127c-4a97-a851-951c96e25976",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evalParams={v:k for k,v in enumerate(['accuracy','falseClassRate','falseNassRate','precision','recall','f1score'\n",
    "                                     ])}\n",
    "\n",
    "for run in modelList: \n",
    "    if not 'Knn' in run:\n",
    "        probColumn = run[:-5]\n",
    "    else:\n",
    "        probColumn = run\n",
    "        \n",
    "    for cat in labels:\n",
    "        if cat=='sentiment':\n",
    "            labelColumn = 'sentimentLabel'\n",
    "            meanCol = 'averageSentiment'\n",
    "            predColumn = run.replace('predicted_',\n",
    "                                     'predictedSentiment_')\n",
    "            probColumn = probColumn.replace('predicted_',\n",
    "                                     'predictedSentiment_')\n",
    "            \n",
    "        if cat=='topic':\n",
    "            labelColumn = 'topicLabel'\n",
    "            meanCol = 'averageTopic'\n",
    "            predColumn = run.replace('predicted_',\n",
    "                                     'predictedTopic_')\n",
    "            probColumn = probColumn.replace('predicted_',\n",
    "                                     'predictedTopic_')\n",
    "            \n",
    "        \n",
    "        \n",
    "        labelSum = {}\n",
    "        for label in labels[cat]: \n",
    "            \n",
    "\n",
    "            labelSum[label]=[\n",
    "                    #calc accuracy - i.e. ratio label present and predicted\n",
    "                    (sum([bool(label in testSentencesLabeled.loc[i,predColumn] and \n",
    "                                       label in testSentencesLabeled.loc[i,labelColumn])\n",
    "                      for i in testSentencesLabeled.index])+sum(\n",
    "                        [bool(label not in testSentencesLabeled.loc[i,predColumn] and\n",
    "                              label not in testSentencesLabeled.loc[i,labelColumn])\n",
    "                         for i in testSentencesLabeled.index]\n",
    "                       )\n",
    "                    )/(\n",
    "                        testSentencesLabeled.shape[0]),\n",
    "                \n",
    "                    #calc ratio of false positives - ratio of labels falsely predicted\n",
    "                        sum([bool(label in testSentencesLabeled.loc[i,predColumn] \n",
    "                                                and label not in testSentencesLabeled.loc[i,labelColumn])\n",
    "                              for i in testSentencesLabeled.index]\n",
    "                       )/(1+sum([bool(label not in testSentencesLabeled.loc[i,labelColumn]) for i in testSentencesLabeled.index])),\n",
    "                    \n",
    "                \n",
    "                \n",
    "                    #calc ratio of false negatives - label not predicted but present in test data\n",
    "                                      sum([bool(label not in testSentencesLabeled.loc[i,predColumn] \n",
    "                                                and label in testSentencesLabeled.loc[i,labelColumn])\n",
    "                              for i in testSentencesLabeled.index]\n",
    "                                         )/(\n",
    "                                            1+sum([bool(label in testSentencesLabeled.loc[i,labelColumn])\n",
    "                              for i in testSentencesLabeled.index]\n",
    "                                         )),\n",
    "                    #calc precision\n",
    "                                    sum([bool(label in testSentencesLabeled.loc[i,labelColumn] and label in testSentencesLabeled.loc[i,predColumn]) \n",
    "                                         for i in testSentencesLabeled.index])/(1+sum(\n",
    "                                        [bool(label in testSentencesLabeled.loc[i,predColumn]) for i in testSentencesLabeled.index]))\n",
    "                ,\n",
    "                    #calc recall\n",
    "                                    sum([bool(label in testSentencesLabeled.loc[i,labelColumn] and label in testSentencesLabeled.loc[i,predColumn]) \n",
    "                                         for i in testSentencesLabeled.index])/(                                                         \n",
    "                                        1+sum([bool(label in testSentencesLabeled.loc[i,labelColumn]\n",
    "                                                   and label in testSentencesLabeled.loc[i,predColumn]) \n",
    "                                             for i in testSentencesLabeled.index])\n",
    "                                        +sum([bool(label in testSentencesLabeled.loc[i,labelColumn]\n",
    "                                                  and label not in testSentencesLabeled.loc[i,predColumn]) \n",
    "                                             for i in testSentencesLabeled.index])\n",
    "                                    )\n",
    "                ]\n",
    "            #calc F1 Score\n",
    "            labelSum[label].append(2*((labelSum[label][evalParams['precision']]*labelSum[label][evalParams['recall']])\n",
    "                                      /\n",
    "                                      (1+labelSum[label][evalParams['precision']]+labelSum[label][evalParams['recall']])))\n",
    "                     \n",
    "            \n",
    "        #store in frame\n",
    "        tempFrame = pd.DataFrame(labelSum,index=list(evalParams.keys()))\n",
    "        \n",
    "        #get means for all values accross different labels within same label category (sentiment, topic)\n",
    "        tempFrame[meanCol] = tempFrame.mean(numeric_only=True,axis=1)\n",
    "        tempFrame = tempFrame.T\n",
    "        for L in tempFrame.index:\n",
    "            for metric in tempFrame.columns:\n",
    "                resultsFrame.loc[(lookupLabels[L],L),\n",
    "                            (metric,run)] = tempFrame.loc[L,metric]\n",
    "                resultsFrame = resultsFrame.copy()\n",
    "\n",
    "# calc total average for each column\n",
    "for col in resultsFrame.columns:\n",
    "    resultsFrame.loc[('average','average'),col] = (\n",
    "        resultsFrame.loc[('topic','averageTopic'),col]+resultsFrame.loc[('sentiment','averageSentiment'),col])/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8426b043-1428-4651-8ff0-3cd420b54886",
   "metadata": {},
   "source": [
    "### Analysis of model results on the best performing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3017a6d4-921c-4b09-98be-8e8e34fc7283",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholdAccuracy=0.65\n",
    "thresholdFalseClass=0.35\n",
    "thresholdFalseNass=0.35\n",
    "\n",
    "filterMaskUnion = sorted(set([i for i in [item[1] for item in resultsFrame.loc[('sentiment','averageSentiment'),['f1score']].sort_values(ascending=False)[:8].index]\n",
    "                                        if resultsFrame.loc[('sentiment','averageSentiment'),('accuracy',i)]>thresholdAccuracy \n",
    "                             and resultsFrame.loc[('sentiment','averageSentiment'),('falseClassRate',i)]<thresholdFalseClass\n",
    "                             and resultsFrame.loc[('sentiment','averageSentiment'),('falseNassRate',i)]<thresholdFalseNass]) \n",
    "                         | \n",
    "                         set([i for i in [item[1] for item in resultsFrame.loc[('topic','averageTopic'),['f1score']].sort_values(ascending=False)[:8].index]\n",
    "                                        if resultsFrame.loc[('topic','averageTopic'),('accuracy',i)]>thresholdAccuracy \n",
    "                             and resultsFrame.loc[('topic','averageTopic'),('falseClassRate',i)]<thresholdFalseClass\n",
    "                             and resultsFrame.loc[('topic','averageTopic'),('falseNassRate',i)]<thresholdFalseNass]\n",
    "                        )\n",
    "                         |set(['predicted_tfidf_Knn_K5'])\n",
    "                        )\n",
    "    \n",
    "\n",
    "plotColumns = ['accuracy','falseClassRate','falseNassRate',\n",
    "               'precision','recall','f1score'\n",
    "              ]\n",
    "plotPredictions = [('sentiment','averageSentiment'),('topic','averageTopic')]\n",
    "plotFrameSentiment = pd.DataFrame([\n",
    "    resultsFrame.loc[plotPredictions[0],(col,filterMaskUnion)].values for col in plotColumns],\n",
    "             columns=[item.replace('predicted_','') for item in filterMaskUnion],index=plotColumns).T\n",
    "plotFrameSentiment['labelType'] = [plotPredictions[0][0]]*plotFrameSentiment.shape[0]\n",
    "plotFrameSentiment = plotFrameSentiment.reset_index().set_index(['labelType','index'])\n",
    "\n",
    "plotFrameTopic = pd.DataFrame([\n",
    "    resultsFrame.loc[plotPredictions[1],(col,filterMaskUnion)].values for col in plotColumns],\n",
    "             columns=[item.replace('predicted_','') for item in filterMaskUnion],index=plotColumns).T\n",
    "plotFrameTopic['labelType'] = [plotPredictions[1][0]]*plotFrameTopic.shape[0]\n",
    "plotFrameTopic = plotFrameTopic.reset_index().set_index(['labelType','index'])\n",
    "plotFrame = pd.concat([plotFrameSentiment,plotFrameTopic])\n",
    "plotFrame = plotFrame.rename(columns={'accuracy':'Accuracy',\n",
    "                                      'falseClassRate':'False Positive Rate',\n",
    "                                     'falseNassRate':'False Negative Rate',\n",
    "                                     'precision':'Precision',\n",
    "                                     'recall':'Recall',\n",
    "                                     'f1score':'F1 Score'\n",
    "                                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bc5f95-b572-4675-bcb7-1d323934be32",
   "metadata": {},
   "outputs": [],
   "source": [
    "filterMaskUnion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6050a67a-e768-49c5-b026-426d566fc880",
   "metadata": {},
   "source": [
    "### Visualization for interpretation of results and for figures in report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21910bb-9ae0-4f4e-845f-07634b884467",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveFig=True\n",
    "print('Results from a vocabulary of '+str(vocabSize)\n",
    "      +' words. Decomposition, where applicable, is at '\n",
    "      +str(nComps)+' dimensions for the Tfidf by use of'\n",
    "      'truncated SVD')\n",
    "display(plotFrame)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('tableau-colorblind10')\n",
    "fig, (sent,top) = plt.subplots(2,1,figsize=(16,10),dpi=240,sharex=True)#,sharey=True)\n",
    "\n",
    "sent = plotFrame.loc['sentiment',['Accuracy','Precision','Recall','F1 Score']].plot.barh(ax=sent, stacked=False, legend=True)\n",
    "sent.set_title('Sentiment prediction results')\n",
    "sent.grid(True)\n",
    "sent.set_ylabel('')\n",
    "top = plotFrame.loc['topic',['Accuracy','Precision','Recall','F1 Score']].plot.barh(ax=top, stacked=False, legend=False)\n",
    "top.set_title('Topic prediction results')\n",
    "top.grid(True)\n",
    "top.set_ylabel('')\n",
    "if saveFig:\n",
    "    filename = 'ModelPerformances_'+str(vocabSize)+'_'+str(nComps)\n",
    "    plt.savefig('results and diagrams/'+filename+'.png')\n",
    "    plotFrame.to_csv('results and diagrams/'+filename+'.csv')\n",
    "    print('figure and csv saved as '+filename)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0f8a66-5173-4917-9558-2e1744781c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotFrame.loc['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61c78a2-1328-4740-992e-3be98a4a4c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveFig=True\n",
    "fig, sent = plt.subplots(1,1,figsize=(12,5),dpi=240,sharex=True)#,sharey=True)\n",
    "\n",
    "sent = plotFrame.loc['sentiment',['Accuracy','Precision','Recall','F1 Score']].plot.barh(ax=sent, stacked=False, legend=True)\n",
    "sent.set_title('Sentiment prediction results',fontsize=20)\n",
    "sent.grid(True)\n",
    "sent.set_ylabel('')\n",
    "\n",
    "if saveFig:\n",
    "    filename = 'ModelPerformances_Sentiment'+str(vocabSize)+'_'+str(nComps)\n",
    "    plt.savefig('results and diagrams/'+filename+'.png')\n",
    "    plotFrame.to_csv('results and diagrams/'+filename+'.csv')\n",
    "    print('figure and csv saved as '+filename)\n",
    "from tabulate import tabulate\n",
    "print(tabulate(plotFrame.loc['sentiment'],tablefmt='latex'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3684992-3f7c-4e00-9a4c-8ded8ffa479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveFig=True\n",
    "plt.style.use('tableau-colorblind10')\n",
    "fig, top = plt.subplots(1,1,figsize=(12,5),dpi=240,sharex=True)#,sharey=True)\n",
    "\n",
    "top = plotFrame.loc['topic',['Accuracy','Precision','Recall','F1 Score']].plot.barh(ax=top, stacked=False, legend=True)\n",
    "top.set_title('Topic prediction results',fontsize=20)\n",
    "top.grid(True)\n",
    "top.set_ylabel('')\n",
    "\n",
    "if saveFig:\n",
    "    filename = 'ModelPerformances_Topic'+str(vocabSize)+'_'+str(nComps)\n",
    "    plt.savefig('results and diagrams/'+filename+'.png')\n",
    "    plotFrame.to_csv('results and diagrams/'+filename+'.csv')\n",
    "    print('figure and csv saved as '+filename)\n",
    "display(plotFrame.loc['sentiment'])\n",
    "from tabulate import tabulate\n",
    "print(tabulate(plotFrame.loc['topic'],tablefmt='latex'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7360126b-3af1-44f9-b674-4467d95f1be4",
   "metadata": {},
   "source": [
    "# Storing essentials from pre-trained models for use in analytics production pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4585b96-3928-4688-bdc4-f4c584fed8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "storeCentroids=True\n",
    "loadCentroids=True\n",
    "storeKnnIngredients=True\n",
    "loadKnnIngredients=True\n",
    "\n",
    "if storeCentroids or storeKnnIngredients:\n",
    "    labelVals = []\n",
    "    for key in labels:\n",
    "        for label in labels[key]:\n",
    "            labelVals.append(label)\n",
    "\n",
    "    centroidContainer = {}\n",
    "    knnIngredients = {}\n",
    "    for rep in trainingReps:\n",
    "        centroidContainer[rep]={}\n",
    "        knnIngredients[rep]={}\n",
    "        for lab in labelVals:\n",
    "            if lab in labels['sentiment']:\n",
    "                K = 'sentiment'\n",
    "            if lab in labels['topic']:\n",
    "                K = 'topic'\n",
    "            lmt = LabelModelTrainer(lab,\n",
    "                                    trainSentencesLabeled[K+'Label'], \n",
    "                                    trainingReps[rep])             \n",
    "            \n",
    "            knnFactors = {'representations':lmt.representations,\n",
    "                         'boolLabels':lmt.boolLabels}\n",
    "            \n",
    "            centroidHolder = {'labelCentroid':lmt.labelCentroid ,\n",
    "                             'othersCentroid':lmt.othersCentroid }\n",
    "            \n",
    "            centroidContainer[rep][lab] = centroidHolder\n",
    "            \n",
    "            knnIngredients[rep][lab] = knnFactors\n",
    "\n",
    "    dump(centroidContainer, 'resources/trainedClassifiers/centroids_vocabSize_'+str(vocabSize)+'_all.joblib')\n",
    "if loadCentroids:\n",
    "    centroidContainer = load('resources/trainedClassifiers/centroids_vocabSize_'+str(vocabSize)+'_all.joblib') \n",
    "if storeKnnIngredients:\n",
    "    dump(knnIngredients, 'resources/trainedClassifiers/knnIngredients_vocabSize_'+str(vocabSize)+'_all.joblib')\n",
    "if loadKnnIngredients:\n",
    "    knnIngredients = load('resources/trainedClassifiers/knnIngredients_vocabSize_'+str(vocabSize)+'_all.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571e8b10-0f95-49b5-acc1-213f0684d953",
   "metadata": {},
   "source": [
    "# Production environment simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5dcbc3-6d51-4079-bbf2-fc18714bff03",
   "metadata": {},
   "source": [
    "## steps prior to the cell below:\n",
    "* ingest, clean, reshape data\n",
    "* index the rows which hold comments (docIdx)\n",
    "* extract only rows with comments\n",
    "* split comments into sentences, keep docIdx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab132b0e-63ec-469c-a95f-f29c6de7fa2a",
   "metadata": {},
   "source": [
    "## Steps after the cell below:\n",
    "* merge with dataframe on docIdx\n",
    "* reshape dataframe so its suited for dashboarding/reports\n",
    "* build reports/dashboards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c3e46d-eedd-474b-a0d2-ada989002e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import nlp \n",
    "from tabulate import tabulate\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.style.use('tableau-colorblind10')\n",
    "\n",
    "vectorizer, svd_tfidf = nlp.loadVectorizerSVD()\n",
    "sentencesLabeled = pd.read_csv(\n",
    "    'resources/trainingData/first_semester_training_data_sentimentTopicLabeled_raw.csv',\n",
    "                                    delimiter=';',\n",
    "                        ).rename(\n",
    "    columns={'Unnamed: 0':'sentIdx',\n",
    "            #'sentence':'sentencePreprocessed',\n",
    "            'label':'sentimentLabel'}).drop(columns=['sentimentLabel','topicLabel'])\n",
    "testSentencesLabeled = sentencesLabeled.loc[round(0.8*sentencesLabeled.shape[0]):].copy()\n",
    "testSentencesLabeled['sentencePreprocessed'] = nlp.preprocessFunction(testSentencesLabeled.sentenceRaw)\n",
    "testSentences_reduced_by_svd = svd_tfidf.transform(vectorizer.transform(testSentencesLabeled.sentencePreprocessed))\n",
    "testSentencesLabeled = testSentencesLabeled.reset_index().merge(nlp.productionPreds(testSentences_reduced_by_svd),left_index=True,right_index=True).set_index(['index']).drop(columns=['sentencePreprocessed'])\n",
    "display(testSentencesLabeled)\n",
    "testDocumentsScored = nlp.dfGrouper(testSentencesLabeled)\n",
    "display(testDocumentsScored)\n",
    "fig, (p1,p2) = plt.subplots(1,2,figsize=(10,3),dpi=240)\n",
    "testDocumentsScored.sentiment_scored.plot.hist(bins=10,title='Distribution of sentiment_scored',ax=p1)\n",
    "p1.set_xlabel('level of satisfaction')\n",
    "p1.grid(True)\n",
    "testDocumentsScored[nlp.Values().validTopics].sum(axis=0).plot.bar(title='Frequency of topics',ax=p2)\n",
    "p2.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
